ðŸ““ Notebook completo: [notebooks/explainable_model.ipynb](notebooks/explainable_model.ipynb)

# -*- coding: utf-8 -*-
"""A4_1diego_machado_xai-.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZsalnK1Vf0kpRQFBeqZy1fYGP8nI0OD_

# Assignment 4
CONTEXT
The doctors of Health Hospital in Zastra are tired of looking at new proposals for detecting heart disease using a Machine Learning model. They wish to understand the model and not rely on a magical black box. Can you help them out by first creating a model and then explaining how these models work?

## ESSENTIALS FOR THE ASSIGNMENT
- Participate in this datathon and submit your predictions in a CSV file by using any model of your choice: https://aiplanet.com/practice/challenge/51

- Perform the tasks given in this notebook: https://aiplanet.com/notebooks/901/gunnika/notebook-submission-template-explainable-ai?. Make sure you write your inferences from each of the visualizations in the space provided. Also, add documentation (comments or Markdown) wherever necessary.

- Submit the above well-documented notebook here: https://aiplanet.com/practice/challenge/51#notebooks

https://aiplanet.com/challenges/51/heart-disease-prediction-51/notebooks/all-notebooks

https://aiplanet.com/learn/machine-learning-bootcamp/module-5-explainable-ai/854/assignment-4

# Task 1

## Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

pd.__version__

"""## Load Data"""

heart_data  = pd.read_csv("https://raw.githubusercontent.com/dphi-official/Datasets/master/Heart_Disease/Training_set_heart.csv" )
heart_data.head(5)

"""## Perform Basic Exploratory Data Analysis"""

heart_data.info()

"""There is no null values in all features, all are numbers and there are few data"""

heart_data.describe()

"""There is not negative values

Let's see if the data is balanced
"""

sum(heart_data['target'])/len(heart_data)

"""It looks balanced! nice"""

sns.pairplot(heart_data)

fig = plt.Figure(figsize=(100,100))
sns.heatmap(heart_data.corr())

"""There **isn't a considerable relationship between variables**, and the **features** that are **more relationed with the target variable are**:


*   cp (+)
*   thalach (+)
* exang(-)
* oldpeak(-)

## Separate the Input and Target Features of the data
"""

y = heart_data['target']
X = heart_data.copy()
del X['target']

X.shape,y.shape

"""## Split the data into Train and Test Sets

"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)



"""Scaling data"""

from sklearn import preprocessing
scaler = preprocessing.StandardScaler().fit(X_train)

Xt_scaled = scaler.transform(X_train)

Xt_scaled = pd.DataFrame(Xt_scaled, columns = X_train.columns)
Xt_scaled

sns.pairplot(Xt_scaled)

"""Scaling the test set"""

Xtest_scaled = scaler.transform(X_test)

"""# Task 2

## Build a Logistic Regression Model on train set
"""

from sklearn.linear_model import LogisticRegression

lrm = LogisticRegression()
lrm.fit(Xt_scaled,y_train)

from sklearn.metrics import f1_score
f1_score(y_train, lrm.predict(Xt_scaled))

f1_score(y_test, lrm.predict(Xtest_scaled))

"""Nice model, doesn't overfitting

# Task 3

## Use a SHAP Explainer to derive SHAP Values for the logistic regression model.
"""

!pip install shap

import shap
explainer = shap.LinearExplainer(lrm, Xt_scaled)

shap_values = explainer.shap_values(Xtest_scaled)
pd.DataFrame(shap_values, columns = X.columns)

expected_value = explainer.expected_value
print('Expected Value: %f' % expected_value)

"""The base value is 0.297744, so those values â€‹â€‹above this number will result in a target value of 1 (presents heart disease), or otherwise a target value 0 (does not present

# Task 4

## Plot a SHAP force plot for the first row of test data.
"""

shap.initjs()
shap.force_plot(expected_value,
                explainer.shap_values(Xtest_scaled)[0,:], X_test.iloc[0,:])

"""chest pain is what most pushes the first patient from the test data to have a positive result, that is, it is estimated that he will suffer from heart disease. Furthermore, Resting electrocardiographic results is the variable that most reduces this probability.

# Task 5

## Plot a SHAP force plot for all the rows of the data
"""

shap.initjs()
shap.force_plot(expected_value, explainer.shap_values(Xtest_scaled), X_test)

"""# Task 6

## Plot a SHAP summary plot using all the features in the data
"""

shap.initjs()
shap.summary_plot(explainer.shap_values(Xtest_scaled),
                  X_test, plot_type="bar")

"""chest pain together with Maximum heart rate achieved is the most important variable when estimating heart disease. On the contrary chol and fbs are the least influential variables"""

shap.initjs()
shap.summary_plot(explainer.shap_values(Xtest_scaled),
                  X_test)

"""Cp and thal present more visible patterns, on the contrary with fbs and chol, which we saw were the least important, that is why the results make sense

# Task 7

## Plot a dependence plot to show the effect of â€˜cholâ€™ across the whole dataset
"""

shap.initjs()
shap.dependence_plot(ind='chol', interaction_index='chol',
                     shap_values=explainer.shap_values(Xtest_scaled),
                     features=X_test)

"""It presents a linear relationship because we are estimating with logistic regression, which behaves linearly, the highest chol values â€‹â€‹are those that generate greater importance for the model"""

features = X.columns.to_list()
features.remove('chol')
print(features )

shap.initjs()
for feature in features:
  shap.dependence_plot(ind='chol', interaction_index=feature,
                     shap_values=explainer.shap_values(Xtest_scaled),
                     features=X_test)

"""We can see that all behaviors are linear

# Test data

### This results to the big Dphi
"""

test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Heart_Disease/Testing_set_heart.csv')
test_data

test_data_scaled = scaler.transform(test_data)
test_data_scaled = pd.DataFrame(test_data_scaled, columns = test_data.columns)
test_data_scaled

predicts = lrm.predict(test_data_scaled)

pred_data = pd.DataFrame(predicts)
#pred_data.index = test_data.index
pred_data.columns = ['prediction']
from google.colab import files
pred_data.to_csv('prediction_results.csv',index = False)
files.download('prediction_results.csv')

"""F1-Score: 83.49"""



"""# My model and approaches

For tree-based methods I shouldn't scale data

### Split Data
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify = y)

sum(y_train)/len(y_train)

"""Balanced test and train set, good

## RandomForest
This was my best results, Didn't be too good, I think because I didn't try a better feature Engenieering and EDA because time ):
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score
rfc = RandomForestClassifier(random_state = 13)
rfc.fit(X_train, y_train)

print("Train F1-Score: %f"%(f1_score(y_train, rfc.predict(X_train))))
print("Test F1-Score: %f"%(f1_score(y_test, rfc.predict(X_test))))

"""This seems to overfitting, let do little hyperparameter tuning"""

rfc_tuned = RandomForestClassifier(random_state = 13, n_estimators=200, max_depth= 4)
rfc_tuned.fit(Xt_scaled, y_train)

print("Train F1-Score: %f"%(f1_score(y_train, rfc_tuned.predict(Xt_scaled))))
print("Test F1-Score: %f"%(f1_score(y_test, rfc_tuned.predict(Xtest_scaled))))

predicts = rfc_tuned.predict(test_data)
pred_data = pd.DataFrame(predicts)
#pred_data.index = test_data.index
pred_data.columns = ['prediction']
from google.colab import files
pred_data.to_csv('prediction_results.csv',index = False)
files.download('prediction_results.csv')

"""Fit All data"""

rfc_tuned = RandomForestClassifier(random_state = 13, n_estimators=200, max_depth= 4)
rfc_tuned.fit(X, y)

predicts = rfc_tuned.predict(test_data)
pred_data = pd.DataFrame(predicts)
#pred_data.index = test_data.index
pred_data.columns = ['prediction']
from google.colab import files
pred_data.to_csv('prediction_results.csv',index = False)
files.download('prediction_results.csv')





from sklearn.model_selection import RandomizedSearchCV
rfc_rs = RandomForestClassifier(random_state=13)
params_rfc = {
    'n_estimators': [200,300,4000],
    'max_depth' : [10,15],
    'min_samples_split' : [5,7,10],

}
clf = RandomizedSearchCV(rfc_rs, params_rfc, scoring='f1',n_jobs = -1,cv=5, random_state=0)

clf.fit(X_train, y_train)

clf.best_params_, clf.best_score_

f1_score(y_test, clf.predict(X_test))

"""## Xgboost"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score

# Assuming you have a DataFrame 'data' with your features and target variable 'target'
# Replace 'data' and 'target' with your actual DataFrame and target column name
# Example:
# data = pd.read_csv('your_data.csv')
# target = 'HeartDisease' # or whatever your target column is called

# Split data into features (X) and target (y)
#X = data.drop(target, axis=1)
#y = data[target]

# Assuming you have X and y defined

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) #Added stratify for imbalance

# Scale the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

Xt_scaled = X_train_scaled #Keeping same names as original code for now
Xtest_scaled = X_test_scaled

####################################################
# XGBoost - Improved with Hyperparameter Tuning
####################################################

import xgboost as xgb
from sklearn.model_selection import GridSearchCV

# Define the parameter grid for XGBoost
param_grid_xgb = {
    'n_estimators': [100, 200, 500],  # Number of boosting rounds
    'max_depth': [3, 5, 7],           # Maximum depth of trees
    'learning_rate': [0.01, 0.05, 0.1], # Step size shrinkage
    'gamma': [0, 0.1, 0.2],          # Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger, the more conservative the algorithm will be.
    'subsample': [0.7, 0.8, 0.9],      # Subsample ratio of the training instance.
    'colsample_bytree': [0.7, 0.8, 0.9] # Subsample ratio of columns when constructing each tree.
}

# Initialize XGBoost classifier
xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42) #Added random_state and eval_metric
#NOTE:  use_label_encoder=False is added to suppress a warning

# Perform GridSearchCV
grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb,
                           scoring='f1', cv=3, n_jobs=-1, verbose=1) #Use verbose=1 or higher to see progress

grid_search_xgb.fit(X_train_scaled, y_train) # Use scaled data

# Print best parameters and score
print("Best parameters (XGBoost):", grid_search_xgb.best_params_)
print("Best F1-score (XGBoost):", grid_search_xgb.best_score_)

# Get the best XGBoost model
best_xgb = grid_search_xgb.best_estimator_

# Evaluate on the test set
test_f1_xgb = f1_score(y_test, best_xgb.predict(X_test_scaled)) #Use scaled data
print("Test F1-score (XGBoost):", test_f1_xgb)


####################################################
# LightGBM - Improved with Hyperparameter Tuning
####################################################

import lightgbm as lgb

# Define the parameter grid for LightGBM
param_grid_lgbm = {
    'num_leaves': [20, 31, 40],      # Number of leaves in one tree
    'max_depth': [-1, 5, 7],           # -1 means no limit
    'learning_rate': [0.01, 0.05, 0.1],
    'feature_fraction': [0.7, 0.8, 0.9], # Subsample ratio of columns when constructing each tree.
    'bagging_fraction': [0.7, 0.8, 0.9], # Subsample ratio of the training instance.
    'bagging_freq': [5, 10],           # frequency for bagging, 0 means disable bagging.
    'min_child_samples': [20, 30, 40]   # Minimum number of data needed in a child(leaf)
}

# Initialize LightGBM classifier
lgbm_model = lgb.LGBMClassifier(objective='binary', metric='binary_logloss', random_state=42, n_jobs=-1)  #Added random_state

# Perform GridSearchCV
grid_search_lgbm = GridSearchCV(estimator=lgbm_model, param_grid=param_grid_lgbm,
                           scoring='f1', cv=3, n_jobs=-1, verbose=1)

grid_search_lgbm.fit(X_train_scaled, y_train) #Use scaled data

# Print best parameters and score
print("Best parameters (LightGBM):", grid_search_lgbm.best_params_)
print("Best F1-score (LightGBM):", grid_search_lgbm.best_score_)

# Get the best LightGBM model
best_lgbm = grid_search_lgbm.best_estimator_

# Evaluate on the test set
test_f1_lgbm = f1_score(y_test, best_lgbm.predict(X_test_scaled)) #Use scaled data
print("Test F1-score (LightGBM):", test_f1_lgbm)

####################################################
# Logistic Regression - Improved with Regularization and Class Weights
####################################################

from sklearn.linear_model import LogisticRegression

# Define the parameter grid for Logistic Regression
param_grid_lr = {
    'C': [0.001, 0.01, 0.1, 1, 10], # Inverse of regularization strength
    'penalty': ['l1', 'l2'],      # Type of regularization
    'solver': ['liblinear', 'saga']   # Algorithm to use in the optimization problem.  'liblinear' good for small datasets
}

# Initialize Logistic Regression classifier
lr_model = LogisticRegression(random_state=42, class_weight='balanced') #Added random_state and class_weight

# Perform GridSearchCV
grid_search_lr = GridSearchCV(estimator=lr_model, param_grid=param_grid_lr,
                           scoring='f1', cv=3, n_jobs=-1, verbose=1)

grid_search_lr.fit(X_train_scaled, y_train) #Use scaled data

# Print best parameters and score
print("Best parameters (Logistic Regression):", grid_search_lr.best_params_)
print("Best F1-score (Logistic Regression):", grid_search_lr.best_score_)

# Get the best Logistic Regression model
best_lr = grid_search_lr.best_estimator_

# Evaluate on the test set
test_f1_lr = f1_score(y_test, best_lr.predict(X_test_scaled)) #Use scaled data
print("Test F1-score (Logistic Regression):", test_f1_lr)

####################################################
# Ensemble - Voting Classifier with Tuned Weights
####################################################

from sklearn.ensemble import VotingClassifier
from sklearn.model_selection import ParameterGrid

# Create the VotingClassifier with the tuned models
voting_clf = VotingClassifier(estimators=[('xgb', best_xgb), ('lgbm', best_lgbm), ('lr', best_lr)], voting='soft') #Use tuned models

# Define a grid of weights to search
wts = {'xgb': 0.4, 'lgbm': 0.4, 'lr': 0.2} # These are good default values

# Fit the VotingClassifier
voting_clf.fit(X_train_scaled, y_train)

# Evaluate the VotingClassifier
test_f1_ensemble = f1_score(y_test, voting_clf.predict(X_test_scaled)) #Use scaled data
print("Test F1-score (Ensemble):", test_f1_ensemble)

####################################################
#  Fit and predict all data with lgbm
####################################################
#This part has been changed to use the best_lgbm model instead of training again.
import pandas as pd
best_lgbm.fit(X, y) #Fit all data

#Load test data
test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Heart_Disease/Testing_set_heart.csv')

#Scale test data.  IMPORTANT:  Use the same scaler that you fit to the TRAINING DATA
test_data_scaled = scaler.transform(test_data)

predicts = best_lgbm.predict(test_data_scaled)
pred_data = pd.DataFrame(predicts)
pred_data.columns = ['prediction']
from google.colab import files
pred_data.to_csv('prediction_results.csv',index = False)
files.download('prediction_results.csv')

!pip install --upgrade scikit-learn
import xgboost as xgb # this imports the xgboost module.
from sklearn import metrics   #Additional scklearn functions
import sklearn # explicitly import the sklearn module.
from xgboost import XGBClassifier
from sklearn.metrics import f1_score

xgb_model = XGBClassifier()
xgb_model.fit(X_train, y_train)
print(xgb.__version__)
print(sklearn.__version__)
#print(xgb.__version__)
#print(sklearn.__version__)

print(xgb.__version__)
print(sklearn.__version__)

pip install xgboost

!pip install scikit-learn==1.2.2
!pip install --upgrade xgboost

from xgboost import XGBClassifier
from sklearn.metrics import f1_score
xgb_model = XGBClassifier()
xgb_model.fit(X_train, y_train)

print("Train F1-Score: %f"%(f1_score(y_train, xgb_model.predict(X_train))))
print("Test F1-Score: %f"%(f1_score(y_test, xgb_model.predict(X_test))))

"""### Hyperparameter Tuning"""

import xgboost as xgb
from sklearn import metrics   #Additional scklearn functions
def modelfit(alg, dtrain, y_train, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):

    if useTrainCV:
        xgb_param = alg.get_xgb_params()
        xgtrain = xgb.DMatrix(dtrain, label=y_train)
        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,
            metrics='auc', early_stopping_rounds=early_stopping_rounds)
        alg.set_params(n_estimators=cvresult.shape[0])

    #Fit the algorithm on the data
    alg.fit(dtrain, y_train,eval_metric='auc')

    #Predict training set:
    dtrain_predictions = alg.predict(dtrain)
    dtrain_predprob = alg.predict_proba(dtrain)[:,1]

    #Print model report:
    print ("\nModel Report")
    print ("Accuracy : %.4g" % metrics.accuracy_score(y_train, dtrain_predictions))
    print ("AUC Score (Train): %f" % metrics.roc_auc_score(y_train, dtrain_predprob))
    print ("F1 Score (Train): %f" % f1_score(y_train, dtrain_predictions))

    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)
    #feat_imp.plot(kind='bar', title='Feature Importances')
    #plt.ylabel('Feature Importance Score')

#Choose all predictors except target & IDcols
predictors = X_train.columns.to_list()
xgb1 = XGBClassifier(
 learning_rate =0.1,
 n_estimators=1000,
 max_depth=10,
 min_child_weight=1,
 gamma=0,
 subsample=0.8,
 colsample_bytree=0.8,
 objective= 'binary:logistic',
 nthread=4,
 scale_pos_weight=1,
 seed=13)
modelfit(xgb1, X_train, y_train, predictors)

print("Test F1-Score: %f"%(f1_score(y_test, xgb1.predict(X_test))))

#TUNING GRID SEARCH
from sklearn.model_selection import GridSearchCV
param_test1 = {
  'n_estimators': [100, 200 , 500, 1000],
 'max_depth':range(3,10,2),
 'min_child_weight':range(1,6,2)
}
gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,
 min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,
 objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27),
 param_grid = param_test1, scoring='f1',n_jobs=-1,iid=False, cv=5)
gsearch1.fit(X_train,y_train)

gsearch1.best_params_, gsearch1.best_score_

print("Test F1-Score: %f"%(f1_score(y_test, xgb1.predict(X_test))))

"""Final Xgboost tuned"""

import xgboost as xgb
xgb_tuned = xgb.XGBClassifier( learning_rate =0.1, n_estimators=100, max_depth=3,
 min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,
 objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)
xgb_tuned.fit(X_train, y_train)

from sklearn.metrics import f1_score
f1_score(y_test, xgb_tuned.predict(X_test))

"""## Lightgbm"""

pip install lightgbm

import lightgbm as lgb
parameters = {
    'application': 'binary',
    'objective': 'binary',
    'metric': 'f1',
    'is_unbalance': 'false',
    'boosting': 'gbdt',
    'num_leaves': 31,
    'feature_fraction': 0.5,
    'bagging_fraction': 0.5,
    'bagging_freq': 20,
    'learning_rate': 0.05,
    'verbose': 0
}

train_data = lgb.Dataset(X_train, label=y_train)
test_data = lgb.Dataset(X_test, label=y_test)

def lgb_f1_score(y_hat, data):
    y_true = data.get_label()
    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities
    return 'f1', f1_score(y_true, y_hat), True

lgb = lgb.train(parameters,
                train_data,
                valid_sets=test_data,
                num_boost_round=5000,
                feval=lgb_f1_score,
                early_stopping_rounds=100)

lgb_predict = lgb.predict(X_test)
lgb_predict = np.where(lgb_predict < 0.5, 0, 1)
f1_score(y_test, lgb_predict)

"""Fit All data"""

import lightgbm as lgb
parameters = {
    'application': 'binary',
    'objective': 'binary',
    'metric': 'f1',
    'is_unbalance': 'false',
    'boosting': 'gbdt',
    'num_leaves': 31,
    'feature_fraction': 0.5,
    'bagging_fraction': 0.5,
    'bagging_freq': 20,
    'learning_rate': 0.05,
    'verbose': 0
}

train_data = lgb.Dataset(X, label=y)

test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Heart_Disease/Testing_set_heart.csv')
test_data

lgb = lgb.train(parameters,
                train_data)

predicts = lgb.predict(test_data)

predicts = np.where(predicts < 0.5, 0, 1)

pred_data = pd.DataFrame(predicts)
#pred_data.index = test_data.index
pred_data.columns = ['prediction']
from google.colab import files
pred_data.to_csv('prediction_results.csv',index = False)
files.download('prediction_results.csv')

"""## LogisticRegression"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()

lr.fit(Xt_scaled, y_train)

print("Train F1-Score: %f"%(f1_score(y_train, lr.predict(Xt_scaled))))
print("Test F1-Score: %f"%(f1_score(y_test, lr.predict(Xtest_scaled))))

"""## Ensemble


*   rf_tuned
*   xgb_tuned
* Logistic


"""

from sklearn.ensemble import VotingClassifier
ensemble = VotingClassifier(estimators=[('lr', lr), ('rf', rfc_tuned)], voting='soft')

ensemble.fit(Xt_scaled, y_train)

Xtest_scaled = pd.DataFrame(Xtest_scaled, columns= Xt_scaled.columns)
f1_score(y_test, ensemble.predict(Xtest_scaled))

f1_score(y_train, ensemble.predict(Xt_scaled))

"""# Gratitude
I always feel that thanking you is little compared to what you do for me, thanks to you I have learned a lot and I have also had a lot of fun, so infinite thanks for your hard work and dedication, I love you.
Atte Diegulio from Chile <3
"""





